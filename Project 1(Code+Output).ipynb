{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cb4d406-0390-4c4d-b4f3-29be19477f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 03:36:40,964 - INFO - WebDriver initialized successfully\n",
      "2025-09-04 03:36:48,881 - INFO - Navigated to FIFA rankings page\n",
      "2025-09-04 03:37:19,250 - INFO - Table loaded with fallback selector\n",
      "2025-09-04 03:37:43,053 - INFO - Completed scrolling and data loading\n",
      "2025-09-04 03:37:46,666 - INFO - Found 10 rows using selector: table tbody tr\n",
      "2025-09-04 03:37:46,717 - INFO - Successfully scraped 10 teams\n",
      "2025-09-04 03:37:46,719 - INFO - Data saved to FIFA_Rankings_Complete_20250904_033746.csv\n",
      "2025-09-04 03:37:46,723 - INFO - Rank range: 1 to 101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Scraping Completed! Data saved to FIFA_Rankings_Complete_20250904_033746.csv\n",
      "Successfully scraped 10 teams\n",
      "Rank range: 1 to 101\n",
      "\n",
      "Top 10 Teams:\n",
      " Rank        Team  Total Points  Previous Points Change Match Window\n",
      "    1   Argentina       1885.36          1886.16   -0.8           DW\n",
      "    2       Spain       1867.09          1854.64 +12.45           LW\n",
      "    3      France       1862.03          1852.71  +9.32           WL\n",
      "    4     England       1813.32          1819.20  -5.88           LW\n",
      "    5      Brazil       1777.69          1776.03  +1.66           WD\n",
      "    8     Belgium       1736.38          1735.75  +0.63           WD\n",
      "   61    Portugal       1770.53          1750.08 +20.45           WW\n",
      "   71 Netherlands       1758.18          1752.44  +5.74           WW\n",
      "   91     Germany       1716.98          1716.98      -           LL\n",
      "  101     Croatia       1707.51          1698.66  +8.85           WW\n",
      "\n",
      "⚠️ Warning: Only 10 teams scraped. FIFA has 211 member associations.\n",
      "This might indicate the page structure has changed or data loading is incomplete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-04 03:37:50,063 - INFO - WebDriver closed successfully\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "DATA ANALYSIS REPORT\n",
      "==================================================\n",
      "Total teams scraped: 10\n",
      "Rank range: 1 - 101\n",
      "Missing ranks in sequence: {6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100}\n",
      "\n",
      "Top 10 teams with highest points:\n",
      " Rank        Team  Total Points\n",
      "    1   Argentina       1885.36\n",
      "    2       Spain       1867.09\n",
      "    3      France       1862.03\n",
      "    4     England       1813.32\n",
      "    5      Brazil       1777.69\n",
      "   61    Portugal       1770.53\n",
      "   71 Netherlands       1758.18\n",
      "    8     Belgium       1736.38\n",
      "   91     Germany       1716.98\n",
      "  101     Croatia       1707.51\n",
      "\n",
      "Data quality metrics:\n",
      "Teams with valid points: 10\n",
      "Teams with change data: 10\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException, WebDriverException\n",
    "from bs4 import BeautifulSoup\n",
    "import logging\n",
    "\n",
    "# Setup logging with UTF-8 encoding\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('fifa_scraper.log', encoding='utf-8'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Setup Chrome WebDriver with optimal options for FIFA site\"\"\"\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--start-maximized\")\n",
    "    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "    \n",
    "    service = Service(r\"C:/Users/Abdullah Umer/Desktop/CodeAlpha Internship/Project 1/chromedriver.exe\")\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    \n",
    "    # Execute script to hide webdriver property\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    return driver\n",
    "\n",
    "def wait_for_complete_table_load(driver, max_wait_time=30):\n",
    "    \"\"\"Wait for complete table loading with multiple strategies\"\"\"\n",
    "    try:\n",
    "        # Strategy 1: Wait for initial table structure\n",
    "        WebDriverWait(driver, max_wait_time).until(\n",
    "            EC.presence_of_element_located((By.CSS_SELECTOR, \"[data-cy='ranking-table'] tbody tr\"))\n",
    "        )\n",
    "        \n",
    "        # Strategy 2: Wait for multiple rows to ensure pagination/loading is complete\n",
    "        WebDriverWait(driver, 15).until(\n",
    "            lambda driver: len(driver.find_elements(By.CSS_SELECTOR, \"[data-cy='ranking-table'] tbody tr\")) > 10\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Complete table structure loaded successfully\")\n",
    "        return True\n",
    "        \n",
    "    except TimeoutException:\n",
    "        # Fallback: Try alternative selectors\n",
    "        try:\n",
    "            WebDriverWait(driver, 15).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, \"table tbody tr\"))\n",
    "            )\n",
    "            logging.info(\"Table loaded with fallback selector\")\n",
    "            return True\n",
    "        except TimeoutException:\n",
    "            raise TimeoutException(\"Failed to load table with all strategies\")\n",
    "\n",
    "def scroll_and_load_all_data(driver):\n",
    "    \"\"\"Scroll through the page to ensure all data is loaded\"\"\"\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    \n",
    "    while True:\n",
    "        # Scroll to bottom\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Check for \"Load More\" button and click if present\n",
    "        try:\n",
    "            load_more_button = driver.find_element(By.CSS_SELECTOR, \"[data-cy='load-more'], .load-more-button, button[aria-label*='more']\")\n",
    "            if load_more_button.is_displayed() and load_more_button.is_enabled():\n",
    "                driver.execute_script(\"arguments[0].click();\", load_more_button)\n",
    "                time.sleep(3)\n",
    "                logging.info(\"Clicked load more button\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Wait for new content to load\n",
    "        time.sleep(2)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        \n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    # Final scroll to top and back to ensure all elements are in view\n",
    "    driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "    time.sleep(1)\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "def clean_team_name(team_text):\n",
    "    \"\"\"Clean team name by removing country codes and extra whitespace\"\"\"\n",
    "    if not team_text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Remove common country code patterns (3 letter codes at end)\n",
    "    cleaned = re.sub(r'[A-Z]{3}$', '', team_text).strip()\n",
    "    \n",
    "    # Remove multiple whitespaces\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "    \n",
    "    # Handle special cases where country code might be in middle\n",
    "    cleaned = re.sub(r'\\s[A-Z]{3}\\s', ' ', cleaned).strip()\n",
    "    \n",
    "    return cleaned if cleaned else team_text\n",
    "\n",
    "def extract_ranking_data(soup):\n",
    "    \"\"\"Extract ranking data from parsed HTML with multiple selector strategies\"\"\"\n",
    "    data = []\n",
    "    \n",
    "    # Strategy 1: Try specific FIFA ranking table selector\n",
    "    selectors = [\n",
    "        \"[data-cy='ranking-table'] tbody tr\",\n",
    "        \"table[class*='ranking'] tbody tr\",\n",
    "        \"table tbody tr\",\n",
    "        \".ranking-table tbody tr\"\n",
    "    ]\n",
    "    \n",
    "    rows = []\n",
    "    for selector in selectors:\n",
    "        rows = soup.select(selector)\n",
    "        if rows:\n",
    "            logging.info(f\"Found {len(rows)} rows using selector: {selector}\")\n",
    "            break\n",
    "    \n",
    "    if not rows:\n",
    "        raise NoSuchElementException(\"No table rows found with any selector strategy\")\n",
    "    \n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            cols = row.find_all(['td', 'th'])\n",
    "            if len(cols) < 3:  # Skip header or incomplete rows\n",
    "                continue\n",
    "                \n",
    "            # Extract data with flexible column handling\n",
    "            rank_text = cols[0].get_text(strip=True) if cols[0] else \"\"\n",
    "            team_text = cols[1].get_text(strip=True) if len(cols) > 1 else \"\"\n",
    "            points_text = cols[2].get_text(strip=True) if len(cols) > 2 else \"\"\n",
    "            prev_points_text = cols[3].get_text(strip=True) if len(cols) > 3 else \"\"\n",
    "            change_text = cols[4].get_text(strip=True) if len(cols) > 4 else \"\"\n",
    "            match_window_text = cols[5].get_text(strip=True) if len(cols) > 5 else \"\"\n",
    "            \n",
    "            # Skip if essential data is missing\n",
    "            if not rank_text or not team_text:\n",
    "                continue\n",
    "            \n",
    "            # Clean and validate rank (should be numeric)\n",
    "            rank_clean = re.sub(r'[^\\d]', '', rank_text)\n",
    "            if not rank_clean.isdigit():\n",
    "                continue\n",
    "            \n",
    "            # Clean team name\n",
    "            team_clean = clean_team_name(team_text)\n",
    "            \n",
    "            # Clean points (remove non-numeric except decimal point)\n",
    "            points_clean = re.sub(r'[^\\d.]', '', points_text) if points_text else \"0\"\n",
    "            prev_points_clean = re.sub(r'[^\\d.]', '', prev_points_text) if prev_points_text else \"0\"\n",
    "            \n",
    "            # Ensure we have valid data\n",
    "            if team_clean and rank_clean:\n",
    "                data.append([\n",
    "                    int(rank_clean),\n",
    "                    team_clean,\n",
    "                    points_clean,\n",
    "                    prev_points_clean,\n",
    "                    change_text,\n",
    "                    match_window_text\n",
    "                ])\n",
    "                \n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Error processing row {i+1}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Sort by rank to ensure correct order\n",
    "    data.sort(key=lambda x: x[0])\n",
    "    \n",
    "    return data\n",
    "\n",
    "def scrape_fifa_rankings():\n",
    "    \"\"\"Main scraping function with enhanced data extraction\"\"\"\n",
    "    driver = None\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        # Setup driver\n",
    "        driver = setup_driver()\n",
    "        logging.info(\"WebDriver initialized successfully\")\n",
    "        \n",
    "        # Navigate to FIFA rankings\n",
    "        driver.get(\"https://www.fifa.com/fifa-world-ranking/men\")\n",
    "        logging.info(\"Navigated to FIFA rankings page\")\n",
    "        \n",
    "        # Wait for complete table loading\n",
    "        wait_for_complete_table_load(driver)\n",
    "        \n",
    "        # Scroll and load all data\n",
    "        scroll_and_load_all_data(driver)\n",
    "        logging.info(\"Completed scrolling and data loading\")\n",
    "        \n",
    "        # Additional wait for any final loading\n",
    "        time.sleep(3)\n",
    "        \n",
    "        # Parse with BeautifulSoup\n",
    "        soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        \n",
    "        # Extract data\n",
    "        data = extract_ranking_data(soup)\n",
    "        \n",
    "        if not data:\n",
    "            raise ValueError(\"No valid data extracted\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(data, columns=[\n",
    "            \"Rank\", \"Team\", \"Total Points\", \"Previous Points\", \"Change\", \"Match Window\"\n",
    "        ])\n",
    "        \n",
    "        # Data validation and cleanup\n",
    "        if df.empty:\n",
    "            raise ValueError(\"DataFrame is empty after processing\")\n",
    "        \n",
    "        # Remove duplicates and sort by rank\n",
    "        df = df.drop_duplicates(subset=['Rank']).sort_values('Rank').reset_index(drop=True)\n",
    "        \n",
    "        # Convert numeric columns\n",
    "        df['Rank'] = pd.to_numeric(df['Rank'], errors='coerce')\n",
    "        df['Total Points'] = pd.to_numeric(df['Total Points'], errors='coerce')\n",
    "        df['Previous Points'] = pd.to_numeric(df['Previous Points'], errors='coerce')\n",
    "        \n",
    "        # Remove rows with invalid ranks\n",
    "        df = df.dropna(subset=['Rank']).reset_index(drop=True)\n",
    "        \n",
    "        # Save with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"FIFA_Rankings_Complete_{timestamp}.csv\"\n",
    "        df.to_csv(filename, index=False, encoding=\"utf-8-sig\")\n",
    "        \n",
    "        # Success logging\n",
    "        logging.info(f\"Successfully scraped {len(df)} teams\")\n",
    "        logging.info(f\"Data saved to {filename}\")\n",
    "        logging.info(f\"Rank range: {df['Rank'].min()} to {df['Rank'].max()}\")\n",
    "        \n",
    "        print(f\"✅ Scraping Completed! Data saved to {filename}\")\n",
    "        print(f\"Successfully scraped {len(df)} teams\")\n",
    "        print(f\"Rank range: {df['Rank'].min()} to {df['Rank'].max()}\")\n",
    "        print(\"\\nTop 10 Teams:\")\n",
    "        print(df.head(10).to_string(index=False))\n",
    "        \n",
    "        if len(df) < 50:\n",
    "            print(f\"\\n⚠️ Warning: Only {len(df)} teams scraped. FIFA has 211 member associations.\")\n",
    "            print(\"This might indicate the page structure has changed or data loading is incomplete.\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except TimeoutException as e:\n",
    "        error_msg = f\"Timeout error: {str(e)}\"\n",
    "        logging.error(error_msg)\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        \n",
    "    except NoSuchElementException as e:\n",
    "        error_msg = f\"Element not found: {str(e)}\"\n",
    "        logging.error(error_msg)\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        \n",
    "    except WebDriverException as e:\n",
    "        error_msg = f\"WebDriver error: {str(e)}\"\n",
    "        logging.error(error_msg)\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Unexpected error: {str(e)}\"\n",
    "        logging.error(error_msg)\n",
    "        print(f\"❌ {error_msg}\")\n",
    "        \n",
    "    finally:\n",
    "        # Cleanup\n",
    "        if driver:\n",
    "            try:\n",
    "                driver.quit()\n",
    "                logging.info(\"WebDriver closed successfully\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error closing WebDriver: {str(e)}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def analyze_scraped_data(df):\n",
    "    \"\"\"Analyze the scraped data for quality and completeness\"\"\"\n",
    "    if df.empty:\n",
    "        return\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"DATA ANALYSIS REPORT\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total teams scraped: {len(df)}\")\n",
    "    print(f\"Rank range: {df['Rank'].min()} - {df['Rank'].max()}\")\n",
    "    print(f\"Missing ranks in sequence: {set(range(1, int(df['Rank'].max()) + 1)) - set(df['Rank'].tolist())}\")\n",
    "    \n",
    "    print(\"\\nTop 10 teams with highest points:\")\n",
    "    top_10 = df.nlargest(10, 'Total Points')[['Rank', 'Team', 'Total Points']]\n",
    "    print(top_10.to_string(index=False))\n",
    "    \n",
    "    print(\"\\nData quality metrics:\")\n",
    "    print(f\"Teams with valid points: {df['Total Points'].notna().sum()}\")\n",
    "    print(f\"Teams with change data: {df['Change'].str.len().gt(0).sum()}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    result_df = scrape_fifa_rankings()\n",
    "    if not result_df.empty:\n",
    "        analyze_scraped_data(result_df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fd94b4-9d43-4bae-929c-967a99383303",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
